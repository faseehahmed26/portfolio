<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Tubules Detection on Breast Carcinoma Whole Slide Images | Faseeh Ahmed Mohammad</title>
<meta name=keywords content="Deep Learning,Computer Vision,HistomicsUI,Python,QuPath,R2U-Net,Horovod,Groovy,Distributed Training,Medical Imaging"><meta name=description content="AI-powered detection system for breast cancer grading using deep learning"><meta name=author content><link rel=canonical href=https://faseehahmed26.github.io/portfolio/publications/tubules-detection/><link crossorigin=anonymous href=/portfolio/assets/css/stylesheet.min.2b833c6baa7a96407c2417c7a4049985b42c21cccc2472abf4603967eafd2273.css integrity="sha256-K4M8a6p6lkB8JBfHpASZhbQsIczMJHKr9GA5Z+r9InM=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/portfolio/assets/js/highlight.min.2eadbb982468c11a433a3e291f01326f2ba43f065e256bf792dbd79640a92316.js integrity="sha256-Lq27mCRowRpDOj4pHwEybyukPwZeJWv3ktvXlkCpIxY=" onload=hljs.initHighlightingOnLoad()></script><link rel=icon href=https://faseehahmed26.github.io/portfolio/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://faseehahmed26.github.io/portfolio/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://faseehahmed26.github.io/portfolio/favicon-32x32.png><link rel=apple-touch-icon href=https://faseehahmed26.github.io/portfolio/apple-touch-icon.png><link rel=mask-icon href=https://faseehahmed26.github.io/portfolio/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://faseehahmed26.github.io/portfolio/publications/tubules-detection/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="Tubules Detection on Breast Carcinoma Whole Slide Images"><meta property="og:description" content="AI-powered detection system for breast cancer grading using deep learning"><meta property="og:type" content="article"><meta property="og:url" content="https://faseehahmed26.github.io/portfolio/publications/tubules-detection/"><meta property="og:image" content="https://faseehahmed26.github.io/portfolio/publications/tubules-detection/tub3.png"><meta property="article:section" content="publications"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://faseehahmed26.github.io/portfolio/publications/tubules-detection/tub3.png"><meta name=twitter:title content="Tubules Detection on Breast Carcinoma Whole Slide Images"><meta name=twitter:description content="AI-powered detection system for breast cancer grading using deep learning"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Publications","item":"https://faseehahmed26.github.io/portfolio/publications/"},{"@type":"ListItem","position":2,"name":"Tubules Detection on Breast Carcinoma Whole Slide Images","item":"https://faseehahmed26.github.io/portfolio/publications/tubules-detection/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Tubules Detection on Breast Carcinoma Whole Slide Images","name":"Tubules Detection on Breast Carcinoma Whole Slide Images","description":"AI-powered detection system for breast cancer grading using deep learning","keywords":["Deep Learning","Computer Vision","HistomicsUI","Python","QuPath","R2U-Net","Horovod","Groovy","Distributed Training","Medical Imaging"],"articleBody":"ðŸ”— Publication Abstract Research Overview I presented our groundbreaking research on tubule detection in breast carcinoma whole slide images at SIIM-CMIMI22 (International Conference On Machine Intelligence in Medical Imaging) at Johns Hopkins Hospital, Baltimore, MD. This work addresses a critical component of the Nottingham Breast Cancer Grading system, automating what has traditionally been a tedious manual process for pathologists.\nTechnical Approach Our system employed the R2U-Net CNN architecture, a specialized recurrent residual convolutional neural network optimized for medical image segmentation. The model was trained on two distinct datasets:\nPublic Dataset: 85 whole slide images (775 x 522) at 40x resolution containing 795 annotated tubules Local Hospital Dataset: 50 whole slide images (40,000 x 40,000) at 40x resolution with approximately 25,000 tubules from Basavatarakam Indo-American Cancer Hospital in Hyderabad, India Distributed Training Innovation A key innovation in our approach was implementing distributed training using Horovod, an open-source framework that leverages data parallelism to optimize resource allocation:\nTrained the model across 4 GPUs simultaneously Achieved 3.9x faster training compared to single-GPU implementation Reduced training time from ~27 hours to just 7 hours for 500 epochs System Architecture The end-to-end pipeline consisted of:\nData Preparation: Pathologists annotated tubules using CADD4MBC (Computer-Aided Detection and Diagnosis for Molecular Breast Cancer), with annotations saved as JSON files Preprocessing: Custom scripts using QuPath and Groovy to extract and prepare training data Model Training: R2U-Net architecture with distributed training via Horovod Integration: Web-based viewer for pathologists to upload, analyze, and review results Results Our model achieved exceptional performance metrics:\nDataset Training F1 Score Training Mean IOU Testing F1 Score Testing Mean IOU Public 0.9974 0.9070 0.9293 0.7537 KMIT 0.9962 0.9116 0.9105 0.8053 These results demonstrate that deep learning approaches can effectively automate tubule detection with high accuracy, potentially reducing pathologistsâ€™ workload and improving diagnostic consistency in breast cancer grading.\nImpact This research represents a significant advancement in computational pathology, offering:\nFaster and more consistent tubule detection for breast cancer grading Reduced burden on pathologists for manual identification A scalable framework that can be extended to other histopathological features Integration with existing clinical workflows through web-based platforms The project demonstrates how deep learning can enhance cancer diagnostics while maintaining the critical role of pathologists in the evaluation process. ","wordCount":"369","inLanguage":"en","image":"https://faseehahmed26.github.io/portfolio/publications/tubules-detection/tub3.png","datePublished":"0001-01-01T00:00:00Z","dateModified":"0001-01-01T00:00:00Z","mainEntityOfPage":{"@type":"WebPage","@id":"https://faseehahmed26.github.io/portfolio/publications/tubules-detection/"},"publisher":{"@type":"Organization","name":"Faseeh Ahmed Mohammad","logo":{"@type":"ImageObject","url":"https://faseehahmed26.github.io/portfolio/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class="header sticky-header"><nav class=nav><div class=logo><a href=https://faseehahmed26.github.io/portfolio/ accesskey=h title="Faseeh Ahmed Mohammad (Alt + H)">Faseeh Ahmed Mohammad</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li></ul></span></div><ul id=menu><li><a href=https://faseehahmed26.github.io/portfolio/ title=Home><span>Home</span></a></li><li><a href=https://faseehahmed26.github.io/portfolio/projects title=Projects><span>Projects</span></a></li><li><a href=https://faseehahmed26.github.io/portfolio/experience title=Experience><span>Experience</span></a></li><li><a href=https://faseehahmed26.github.io/portfolio/publications title=Publications><span>Publications</span></a></li><li><a href=https://faseehahmed26.github.io/portfolio/search title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://faseehahmed26.github.io/portfolio/tags title=Tags><span>Tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://faseehahmed26.github.io/portfolio/>Home</a>&nbsp;Â»&nbsp;<a href=https://faseehahmed26.github.io/portfolio/publications/>Publications</a></div><h1 class=post-title>Tubules Detection on Breast Carcinoma Whole Slide Images</h1><div class=post-description>AI-powered detection system for breast cancer grading using deep learning</div><div class=post-meta>Sep 2022</div></header><figure class=entry-cover><img loading=lazy src=https://faseehahmed26.github.io/portfolio/publications/tubules-detection/tub3.png alt></figure><div class=post-content><h3 id=-publication-abstract>ðŸ”— <a href=https://cdn.ymaws.com/siim.org/resource/resmgr/mimi22/abstracts/Tubules_Detection_on_Breast_.pdf>Publication Abstract</a><a hidden class=anchor aria-hidden=true href=#-publication-abstract>#</a></h3><h2 id=research-overview>Research Overview<a hidden class=anchor aria-hidden=true href=#research-overview>#</a></h2><p>I presented our groundbreaking research on tubule detection in breast carcinoma whole slide images at SIIM-CMIMI22 (International Conference On Machine Intelligence in Medical Imaging) at Johns Hopkins Hospital, Baltimore, MD. This work addresses a critical component of the Nottingham Breast Cancer Grading system, automating what has traditionally been a tedious manual process for pathologists.</p><h2 id=technical-approach>Technical Approach<a hidden class=anchor aria-hidden=true href=#technical-approach>#</a></h2><p>Our system employed the R2U-Net CNN architecture, a specialized recurrent residual convolutional neural network optimized for medical image segmentation. The model was trained on two distinct datasets:</p><ul><li><strong>Public Dataset</strong>: 85 whole slide images (775 x 522) at 40x resolution containing 795 annotated tubules</li><li><strong>Local Hospital Dataset</strong>: 50 whole slide images (40,000 x 40,000) at 40x resolution with approximately 25,000 tubules from Basavatarakam Indo-American Cancer Hospital in Hyderabad, India</li></ul><h2 id=distributed-training-innovation>Distributed Training Innovation<a hidden class=anchor aria-hidden=true href=#distributed-training-innovation>#</a></h2><p>A key innovation in our approach was implementing distributed training using Horovod, an open-source framework that leverages data parallelism to optimize resource allocation:</p><ul><li>Trained the model across 4 GPUs simultaneously</li><li>Achieved 3.9x faster training compared to single-GPU implementation</li><li>Reduced training time from ~27 hours to just 7 hours for 500 epochs</li></ul><h2 id=system-architecture>System Architecture<a hidden class=anchor aria-hidden=true href=#system-architecture>#</a></h2><p>The end-to-end pipeline consisted of:</p><ol><li><strong>Data Preparation</strong>: Pathologists annotated tubules using CADD4MBC (Computer-Aided Detection and Diagnosis for Molecular Breast Cancer), with annotations saved as JSON files</li><li><strong>Preprocessing</strong>: Custom scripts using QuPath and Groovy to extract and prepare training data</li><li><strong>Model Training</strong>: R2U-Net architecture with distributed training via Horovod</li><li><strong>Integration</strong>: Web-based viewer for pathologists to upload, analyze, and review results</li></ol><h2 id=results>Results<a hidden class=anchor aria-hidden=true href=#results>#</a></h2><p>Our model achieved exceptional performance metrics:</p><table><thead><tr><th>Dataset</th><th>Training F1 Score</th><th>Training Mean IOU</th><th>Testing F1 Score</th><th>Testing Mean IOU</th></tr></thead><tbody><tr><td>Public</td><td>0.9974</td><td>0.9070</td><td>0.9293</td><td>0.7537</td></tr><tr><td>KMIT</td><td>0.9962</td><td>0.9116</td><td>0.9105</td><td>0.8053</td></tr></tbody></table><p>These results demonstrate that deep learning approaches can effectively automate tubule detection with high accuracy, potentially reducing pathologists&rsquo; workload and improving diagnostic consistency in breast cancer grading.</p><h2 id=impact>Impact<a hidden class=anchor aria-hidden=true href=#impact>#</a></h2><p>This research represents a significant advancement in computational pathology, offering:</p><ul><li>Faster and more consistent tubule detection for breast cancer grading</li><li>Reduced burden on pathologists for manual identification</li><li>A scalable framework that can be extended to other histopathological features</li><li>Integration with existing clinical workflows through web-based platforms</li></ul><p>The project demonstrates how deep learning can enhance cancer diagnostics while maintaining the critical role of pathologists in the evaluation process.
<img loading=lazy src=/publications/tubules-detection/tub3.png#center alt></p><p><img loading=lazy src=/publications/tubules-detection/horovord.png alt></p></div><footer class=post-footer><ul class=post-tags><li><a href=https://faseehahmed26.github.io/portfolio/tags/deep-learning/>Deep Learning</a></li><li><a href=https://faseehahmed26.github.io/portfolio/tags/computer-vision/>Computer Vision</a></li><li><a href=https://faseehahmed26.github.io/portfolio/tags/histomicsui/>HistomicsUI</a></li><li><a href=https://faseehahmed26.github.io/portfolio/tags/python/>Python</a></li><li><a href=https://faseehahmed26.github.io/portfolio/tags/qupath/>QuPath</a></li><li><a href=https://faseehahmed26.github.io/portfolio/tags/r2u-net/>R2U-Net</a></li><li><a href=https://faseehahmed26.github.io/portfolio/tags/horovod/>Horovod</a></li><li><a href=https://faseehahmed26.github.io/portfolio/tags/groovy/>Groovy</a></li><li><a href=https://faseehahmed26.github.io/portfolio/tags/distributed-training/>Distributed Training</a></li><li><a href=https://faseehahmed26.github.io/portfolio/tags/medical-imaging/>Medical Imaging</a></li></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://faseehahmed26.github.io/portfolio/>Faseeh Ahmed Mohammad</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>